\documentclass{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage[margin=1.25in]{geometry}
\usepackage{graphicx, hyperref, float, multicol, pdflscape, enumerate, paralist}
\usepackage{amssymb,amsmath,amsthm} 
\usepackage[backend=bibtex, natbib=true]{biblatex}
\addbibresource{../references/references.bib}

\usepackage{color}
\newcommand{\ak}[1]{{\color{magenta} #1}}
\newcommand{\mj}[1]{{\color{blue} #1}}

\theoremstyle{plain}
\newtheorem{res}{Result}

\setlength{\parindent}{0cm}
\renewcommand{\baselinestretch}{1.5}

\title{Extensive Assignment 1 \\ {STAT 601}}
\author{Andee Kaplan \& Maggie Johnson}
\date{February 28, 2014}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}

\begin{document}

\maketitle



\section*{Model}
Let $\{Y_{ij}: i=1,\dots,n_j, j=1,\dots,m\}$ represent the quantity of green beans sold on day $i$ at store $j$, let $\{Z_{ij}: i=1,\dots,n_j, j=1,\dots,m\}$ represent the unobservable construct of consumer interest on day $i$ at store $j$, and let $\{x_{ij}: i=1,\dots,n_j, j=1,\dots,m\}$ be the price of green beans on day $i$ at store $j$. There are $m=191$ stores in the midwest region. Then, we impose the following model.
\begin{align*}
Z_{ij} &\stackrel{\text{iid}}{\sim} \text{Bern}(p_{ij}) \\
Y_{ij} | Z_{ij} = 1 &\stackrel{\text{indep}}{\sim} \text{Pois}(\lambda_{ij}) \\
Pr(Y_{ij} =0| Z_{ij} = 0) &= 1
\end{align*}

This yields the following marginal distribution of $Y_{ij}$ for $\lambda_{ij} > 0$ and $0 < p_{ij} < 1$:
$$
f(y_{ij}|p_{ij}, \lambda_{ij}) = \left[(1-p_{ij}) + p_{ij} \exp(-\lambda_{ij})\right] \mathbb{I}\{y_{ij} = 0\} + \left[ \frac{p_{ij}}{y_{ij} !} \lambda_{ij}^{y_{ij}}\exp(-\lambda_{ij}) \right]\mathbb{I}\{y_{ij} > 0\}
$$

\subsection*{Systematic Components}
We would like to have both the parameters $p_{ij}$ from the Bernoulli distribution and the parameters $\lambda_{ij}$ from the Poisson portion of the model to be further modeled as a function of price ($x_{ij}$). So, we will use the constructs of GLM to model the expected values of $Y_{ij}$ and $Z_{ij}$ as inverse link functions of the simple regression equations.
\begin{align*}
\text{E}(Z_{ij}) &= p_{ij} \\
\text{E}(Y_{ij}) &= \sum\limits_{y_{ij} = 1}^\infty p_{ij} y_{ij} \lambda_{ij}^{y_{ij}} \exp(-\lambda_{ij}) \\
&= \sum\limits_{y_{ij} = 0}^\infty p_{ij} y_{ij} \lambda_{ij}^{y_{ij}} \exp(-\lambda_{ij}) \\
&= p_{ij} \lambda_{ij}
\end{align*}
We will use a logit-link for $\text{E}(Z_{ij}) $ and a log-link for $\text{E}(Y_{ij})$, which yields the following values.
\begin{align*}
\log\left( \frac{p_{ij}}{1-p_{ij}}\right) &= \beta_0 + \beta_1 x_{ij} \\ 
\Rightarrow p_{ij} &= \frac{\exp(\beta_0 + \beta_1 x_{ij})}{1 + \exp(\beta_0 + \beta_1 x_{ij})} \\
~\\
\log(p_{ij} \lambda_{ij}) &= \beta_2 + \beta_3 x_{ij} \\
p_{ij} \lambda_{ij} &= \exp(\beta_2 + \beta_3 x_{ij}) \\
\Rightarrow \lambda_{ij} &= \frac{ \exp(\beta_2 + \beta_3 x_{ij})}{ \exp(\beta_0 + \beta_1 x_{ij})} (1 +  \exp(\beta_0 + \beta_1 x_{ij}))
\end{align*}

\subsection*{Likelihood}
To obtain the store likelihood $L_j(\beta_0, \beta_1, \beta_2, \beta_3, \beta_4)$, first we will write the joint density for store $j$.
\begin{align*}
L_j(\beta_0, \beta_1, \beta_2, \beta_3, \beta_4) &= f(y_{1j}, \dots, y_{{n_j},j} | \beta_0, \beta_1, \beta_2, \beta_3, \beta_4) \\
&= \prod\limits_{i=1}^{n_j} f(y_{ij}|\beta_0, \beta_1, \beta_2, \beta_3, \beta_4) \tag{\text{independence}} \\
&= \prod\limits_{i=1}^{n_j} \left(\left[(1-p_{ij}(\boldsymbol \beta)) + p_{ij}(\boldsymbol \beta) \exp(-\lambda_{ij}(\boldsymbol \beta))\right] \mathbb{I}\{y_{ij} = 0\} + \right. \\
& \qquad \qquad \left. \left[ \frac{p_{ij}(\boldsymbol \beta)}{y_{ij} !} \lambda_{ij}(\boldsymbol \beta)^{y_{ij}}\exp(-\lambda_{ij}(\boldsymbol \beta)) \right]\mathbb{I}\{y_{ij} > 0\} \right)
\end{align*}

\end{document}
